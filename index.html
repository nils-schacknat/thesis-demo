<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Thesis Demo</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/Dante-alighieri.jpeg">
  <style>
    code {
      color: #555;                   /* Dark gray text instead of bright red */
      background-color: #f5f5f5;     /* Very light gray background */
      padding: 2px 4px;              /* Small padding for readability */
      border-radius: 4px;            /* Rounded corners */
      font-family: Menlo, Monaco,      /* Monospaced font */
                   Consolas, "Courier New", monospace;
      font-size: 0.95em;             /* Slightly smaller than surrounding text */
    }
    /* ============================
       GENERAL GRID / VIDEO STYLES
       ============================ */
    .grid-container {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      grid-template-rows: repeat(4, auto);
      gap: 2px;
      width: 100%;
      /* height: 100%;   ← removed so grid only grows to content */
    }
    .grid-container img {
      width: 100%;
      height: auto;
      display: block;
      cursor: pointer;
      transition: opacity 0.2s ease;
    }
    .grid-container img:hover {
      opacity: 0.8;
    }

    .video-pair-with-grid-wrapper {
      display: flex;
      gap: 20px;
      align-items: stretch;
      margin: 0 auto;
    }

    /* ================================================================================
       FIRST SECTION (compact‐image‐column + top video). We keep flex slots even if hidden
       ================================================================================ */
    .compact-image-column {
      flex: 0.5;
      height: 100%;
      display: flex;
      flex-direction: column;
      justify-content: flex-start;
      visibility: visible; /* toggled via JS */
    }
    .compact-image-column.hidden {
      visibility: hidden; /* hides content but keeps the flex width */
    }
    .video-column {
      flex: 2;
      display: flex;
      flex-direction: column;
      justify-content: flex-start;
    }
    .video-wrapper {
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .video-wrapper video {
      width: 100%;
      height: auto;
      object-fit: contain;
    }
    .video-box {
      flex: 1;
      display: flex;
      flex-direction: column;
    }

    /* ================================================================================
       SECOND SECTION (always‐on overlayed grid + validation/source video)
       ================================================================================ */
    .media-wrapper {
      display: flex;
      gap: 40px;
      align-items: stretch;
    }
    .image-column {
      flex: 1;
      display: flex;
      flex-direction: column;
      justify-content: flex-start;
    }
    .grid-wrapper {
      width: 100%;
      flex: 1;
      display: flex;
      flex-direction: column;
    }
    /* video-column already defined above */

    /* ======================
       MODAL STYLES
       ====================== */
    .modal {
      display: none;
      position: fixed;
      z-index: 1000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.9);
      animation: fadeIn 0.3s ease;
    }
    .modal.show {
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .modal-content {
      max-width: 90%;
      max-height: 90%;
      object-fit: contain;
      border-radius: 8px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
    }
    .modal-close {
      position: absolute;
      top: 20px;
      right: 35px;
      color: #fff;
      font-size: 40px;
      font-weight: bold;
      cursor: pointer;
      transition: color 0.3s ease;
    }
    .modal-close:hover,
    .modal-close:focus {
      color: #ccc;
    }
    @keyframes fadeIn {
      from { opacity: 0; }
      to { opacity: 1; }
    }

    /* ======================
       MISCELLANEOUS STYLES
       ====================== */
    .caption {
      font-size: 1.25rem;
      font-weight: 500;
      text-align: center;
      margin-bottom: 1rem;
      flex-shrink: 0;
    }
  </style>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script>
    // ===================
    //  MODAL FUNCTIONALITY
    // ===================
    function openModal(imageSrc) {
      const modal = document.getElementById('imageModal');
      const modalImg = document.getElementById('modalImage');
      
      modalImg.src = imageSrc;
      modalImg.style.height = '600px';
      modalImg.style.width  = 'auto';
      modal.classList.add('show');
      
      // Prevent body scrolling when modal is open
      document.body.style.overflow = 'hidden';
    }

    function closeModal() {
      const modal = document.getElementById('imageModal');
      modal.classList.remove('show');
      
      // Restore body scrolling
      document.body.style.overflow = 'auto';
      modalImg.style.height = '';
      modalImg.style.width  = '';
    }

    function makeImageClickable(img) {
      img.addEventListener('click', function() {
        openModal(this.src);
      });
    }

    // Close modal when clicking outside the image
    document.addEventListener('DOMContentLoaded', function() {
      const modal = document.getElementById('imageModal');
      modal.addEventListener('click', function(e) {
        if (e.target === modal) {
          closeModal();
        }
      });
      
      // Close modal on escape key
      document.addEventListener('keydown', function(e) {
        if (e.key === 'Escape') {
          closeModal();
        }
      });
    });

    // For the bottom section's "Validation/Source Sequence" video:
    function changeVideo() {
      const selector = document.getElementById('videoSelector');
      const video    = document.getElementById('mainVideo');
      const selectedValue = selector.value;
      video.src = selectedValue;
      video.load();
      video.playbackRate = 0.75;
      video.play();
    }
  </script>
  <script>
    // ===================
    //  DATA & STATE
    // ===================
    const methods   = ["dante-8", "dante-1", "bensaid-8", "v-strong", "wvn-v2"];
    const method_names = ["DANTE (8)", "DANTE (1)", "Bensaid et al. (8)", "V-STRONG", "WVN-v2"];
    const sequences = ["park-2", "trail-12", "village"];
    let currentSequence = sequences[0];
    let currentMethod   = methods[0];
    let isFirstSequenceLoad = true;

    function buildVideoPath(method, sequence) {
      return `./static/videos/${method}/${method}_${sequence}.mp4`;
    }

    // ===================
    //  TOP VIDEO UPDATES
    // ===================
    function updateVideoMethod() {
      const video      = document.getElementById('topVideo');
      const newSrc     = buildVideoPath(currentMethod, currentSequence);
      const prevTime   = video.currentTime;
      const wasPlaying = !video.paused; // remember if it was playing

      video.src = newSrc;
      video.load();
      video.playbackRate = 0.5;

      const onLoaded = () => {
        if (video.duration > prevTime) {
          video.currentTime = prevTime;
        }
        if (wasPlaying) {
          video.play();
          // Hide controls after starting playback
          setTimeout(() => {
            video.controls = false;
          }, 100);
        }
        // if it was paused before, leave it paused
        video.removeEventListener('loadedmetadata', onLoaded);
      };
      video.addEventListener('loadedmetadata', onLoaded);
    }

    function updateVideoSequence() {
      const video  = document.getElementById('topVideo');
      const newSrc = buildVideoPath(currentMethod, currentSequence);

      video.src = newSrc;
      video.load();
      video.playbackRate = 0.5;

      const onLoaded = () => {
        video.currentTime = 0;

        // Only autoplay if we've already done the first load
        if (!isFirstSequenceLoad) {
          video.play();
          // hide controls after playback starts (same as before)
          setTimeout(() => {
            video.controls = false;
          }, 100);
        }

        // Once we've hit this point, clear the "first load" flag
        isFirstSequenceLoad = false;
        video.removeEventListener('loadedmetadata', onLoaded);
      };
      video.addEventListener('loadedmetadata', onLoaded);
    }


    function onSequenceChange() {
      currentSequence = document.getElementById('sequenceSelector').value;
      updateVideoSequence();
    }

    // ===================
    //  IMAGE COLUMN LOGIC
    // ===================
    function updateImageColumn() {
      const imgCol = document.querySelector('.compact-image-column');
      const grid   = document.getElementById('gridContainer2');
      grid.innerHTML = ""; // clear prior content

      if (currentMethod === 'dante-8') {
        imgCol.classList.remove('hidden');
        for (let i = 0; i < 8; i++) {
          const img = document.createElement('img');
          img.src = `./static/images/dante-8/image_${i}.jpg`;
          img.alt = `img${i + 1}`;
          makeImageClickable(img); // Add click functionality
          grid.appendChild(img);
        }
      }
      else if (currentMethod === 'dante-1') {
        imgCol.classList.remove('hidden');
        const img = document.createElement('img');
        img.src = `./static/images/dante-1/image_0.jpg`;
        img.alt = 'img1';
        makeImageClickable(img); // Add click functionality
        grid.appendChild(img);
      }
      else {
        imgCol.classList.add('hidden');
      }
    }

    function onMethodChange() {
      currentMethod = document.getElementById('methodSelector').value;
      updateVideoMethod();
      updateImageColumn();
    }

    // ===================
    //  INITIALIZATION
    // ===================
    document.addEventListener('DOMContentLoaded', () => {
      // Populate sequence dropdown
      const seqSelect = document.getElementById('sequenceSelector');
      sequences.forEach(seq => {
        const opt = document.createElement('option');
        opt.value = seq;
        opt.textContent = seq;
        seqSelect.appendChild(opt);
      });
      seqSelect.value = currentSequence;
      seqSelect.addEventListener('change', onSequenceChange);

      // Populate method dropdown
      const methodSelect = document.getElementById('methodSelector');
      methods.forEach((method, idx) => {
        const opt = document.createElement('option');
        opt.value = method;
        opt.textContent = method_names[idx];
        methodSelect.appendChild(opt);
      });
      methodSelect.value = currentMethod;
      methodSelect.addEventListener('change', onMethodChange);

      // Initialize both top video + image column
      updateVideoSequence();
      updateImageColumn();

      const mainVideo = document.getElementById('mainVideo');
      mainVideo.playbackRate = 0.75;

      // Add hover/click functionality to show controls for the top video
      const topVideo = document.getElementById('topVideo');
      let hideControlsTimeout;
      
      // Show controls on mouse movement within video
      topVideo.addEventListener('mousemove', () => {
        topVideo.controls = true;
        
        // Clear any existing timeout
        if (hideControlsTimeout) {
          clearTimeout(hideControlsTimeout);
        }
        
        // Set new timeout to hide controls
        hideControlsTimeout = setTimeout(() => {
          if (!topVideo.paused) {
            topVideo.controls = false;
          }
        }, 2000);
      });
      
      // Hide controls when mouse leaves video area
      topVideo.addEventListener('mouseleave', () => {
        if (hideControlsTimeout) {
          clearTimeout(hideControlsTimeout);
        }
        if (!topVideo.paused) {
          topVideo.controls = false;
        }
      });
      
      // Show controls on click
      topVideo.addEventListener('click', () => {
        topVideo.controls = true;
        
        // Clear any existing timeout
        if (hideControlsTimeout) {
          clearTimeout(hideControlsTimeout);
        }
        
        // Set new timeout to hide controls
        hideControlsTimeout = setTimeout(() => {
          if (!topVideo.paused) {
            topVideo.controls = false;
          }
        }, 2000);
      });
    });
  </script>
</head>
<body>
  <!-- Modal for enlarged images -->
  <div id="imageModal" class="modal">
    <button class="modal-close is-large" aria-label="close" onclick="closeModal()"></button>
    <img id="modalImage" class="modal-content" alt="Enlarged view">
  </div>

  <nav class="navbar" role="navigation" aria-label="main navigation">
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
        <h1 class="title is-1 publication-title">
          Leveraging Depth-Aware Representations for Few-Shot Traversability Estimation
        </h1>
        <h2 class="subtitle is-4 mt-4">
          Nils Schacknat
        </h2>
      </div>
    </div>
  </section>
  
  <section class="section" style="margin: -50px 0 -60px 0;">
    <div class="container">
      <div class="content">
        <p>This website aims to support the qualitative evaluation of my master's thesis, which addresses the task of vision-based traversability estimation.</p>
        <p>
          My thesis identifies <em>Depth Anything v2</em> as an ideal task-aligned foundational model and proposes to leverage its depth-aware and semantically rich patch embeddings for few-shot segmentation. Further, it demonstrates that, with the <em>Depth Anything v2</em> encoder as a backbone, a simple linear layer trained on only a few manual annotations can reliably predict traversability. A complementary instance selection strategy ensures that the training set remains both diverse and representative.
        </p>
        <p>
          This method &mdash; termed <strong>DANTE</strong> (<em><strong>D</strong>epth <strong>AN</strong>ything based <strong>T</strong>raversability <strong>E</strong>stimation</em>) &mdash; requires minimal supervision and confidently surpasses recent pose-projection-based methods while running at real-time speeds.
          The video below demonstrates the performance on two sequences recorded at the Fraunhofer IPA / Stuttgart University campus, when trained with only eight manually annotated images taken from the “Source Sequence”.
        </p>
      </div>
    </div>
  </section>

  <!-- <section class="section" style="margin: -50px 0;">
    <div class="container">
      <div class="content">
        <h1 class="title is-4">Evaluation on the Fraunhofer IPA / Stuttgart University Campus</h1>
        <p>
          This section showcases predictions on two video sequences recorded on the Fraunhofer&nbsp;IPA / Stuttgart University campus. 
          The scenes span indoor corridors, paved paths, grassy areas, and leaf-covered ground. 
          One video serves as the source sequence &mdash; from which all training images are drawn &mdash; 
          while the other functions as a validation sequence.
        </p> 
      </div>
    </div>
  </section> -->

  <!-- Second section: Always‐on overlayed grid + validation/source video -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="media-wrapper">
        <!-- Left: Always‐on Training Images (overlayed) -->
        <div class="image-column">
          <div class="caption">Training Images</div>
          <div class="grid-wrapper">
            <div id="gridContainer" class="grid-container"></div>
            <script>
              // Hard‐coded eight overlayed images with click functionality
              for (let i = 0; i < 8; i++) {
                const img = document.createElement('img');
                img.src = `./static/images/overlayed/${i}.jpg`;
                img.alt = `img${i + 1}`;
                makeImageClickable(img); // Add click functionality
                document.getElementById('gridContainer').appendChild(img);
              }
            </script>
          </div>
        </div>

        <!-- Right: Validation / Source Sequence video -->
        <div class="video-column video-container">
          <div style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin-bottom: 1rem;">
            <div class="caption" style="margin-bottom: 0;">Results:</div>
            <select id="videoSelector"
                    onchange="changeVideo()"
                    style="padding: 0.5rem; font-size: 1rem; border-radius: 4px; border: 1px solid #ccc;">
              <option value="./static/videos/data_ipa_val.mp4">Validation Sequence</option>
              <option value="./static/videos/data_ipa_train.mp4">Source Sequence</option>
            </select>
          </div>
          <div class="video-wrapper">
            <video id="mainVideo" controls autoplay muted loop playsinline>
              <source src="./static/videos/data_ipa_val.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="content">
        <h1 class="title is-4">Evaluation on RUGD</h1>
        <p>
          This section presents full-sequence predictions on the
          RUGD dataset and compares four approaches:
          <a href="https://arxiv.org/abs/2401.11311" target="_blank" rel="noopener noreferrer">Bensaid et al.</a> (DINOv2 backbone with a linear probe), 
          <a href="https://arxiv.org/abs/2404.07110" target="_blank" rel="noopener noreferrer">Wild Visual Navigation v2</a> (Frey et al.), 
          <a href="https://arxiv.org/abs/2312.16016" target="_blank" rel="noopener noreferrer">V-STRONG</a> (Jung et al.) 
          and DANTE (the proposed method).
        </p>
        <p>
          All methods were trained on the sequences <code>park-1, trail, trail-3, trail-4, trail-5</code>.
          The pose-projection-based approaches, V-STRONG and WVN-v2, receive poses obtained via visual odometry,
          while the few-shot segmentation methods, DANTE and Bensaid et al., use ground-truth masks.
          Predictions are shown for the <code>park-2, trail-12, village</code> sequences. Note that the
          <code>village</code> environment is absent from the training data, providing an out-of-domain test case.
          For few-shot segmentation methods, the number of training images is indicated in parentheses.
        </p>    
      </div>
    </div>
  </section>

  <!-- First section: Video + (potential) image grid, with Sequence and Method selectors on the same line -->
  <section class="section" style="margin: -50px 0 0 0;">
    <div class="container is-max-desktop">
      <div class="video-pair-with-grid-wrapper">
        <!-- Left: Image column (always occupies its flex share, but hidden if no images) -->
        <div class="compact-image-column">
          <div class="caption">Training Images</div>
          <div id="gridContainer2" class="grid-container">
            <!-- JS will inject up to 8 images, or 1 image, or leave blank -->
          </div>
        </div>

        <!-- Right: Video + Sequence & Method Selectors -->
        <div class="video-box video-column">
          <!-- Combined wrapper to keep both selectors on one line -->
          <div style="display: flex; align-items: center; justify-content: center; gap: 2rem; margin-bottom: 1rem;">
            <!-- Sequence selector block -->
            <div style="display: flex; align-items: center; gap: 0.5rem;">
              <div class="caption" style="margin-bottom: 0;">Sequence:</div>
              <select id="sequenceSelector"
                      style="padding: 0.5rem; font-size: 1rem; border-radius: 4px; border: 1px solid #ccc;">
                <!-- Populated dynamically -->
              </select>
            </div>
            <!-- Method selector block -->
            <div style="display: flex; align-items: center; gap: 0.5rem;">
              <div class="caption" style="margin-bottom: 0;">Method:</div>
              <select id="methodSelector"
                      style="padding: 0.5rem; font-size: 1rem; border-radius: 4px; border: 1px solid #ccc;">
                <!-- Populated dynamically -->
              </select>
            </div>
          </div>
          <div class="video-wrapper">
            <video id="topVideo" controls muted playsinline>
              <!-- Source set dynamically by JS -->
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is based on <strong>Nerfies</strong> and licensed under a 
              <a
                rel="license"
                href="https://creativecommons.org/licenses/by-sa/4.0/"
                target="_blank"
                rel="noopener noreferrer"
              >
                Creative Commons Attribution-ShareAlike 4.0 International License
              </a>.
              This means you are free to borrow the source code — please link back to 
              <a
                href="https://github.com/nerfies/nerfies.github.io"
                target="_blank"
                rel="noopener noreferrer"
              >
                the original project
              </a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>
